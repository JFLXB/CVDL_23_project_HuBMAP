{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkpoints import CHECKPOINT_DIR\n",
    "from figures import FIGURES_DIR\n",
    "\n",
    "import torch\n",
    "\n",
    "from hubmap.visualization import visualize_result\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots as _\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"science\", \"nature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 = torch.load(\"/home/jflxb/Documents/lmu/HuBMAP/checkpoints/TransResUNet/wide_resnet50_2_x256.pt\")\n",
    "ckpt2 = torch.load(\"/home/jflxb/Documents/lmu/HuBMAP/checkpoints/TransResUNet/resnext101_32x8d_x512.pt\")\n",
    "\n",
    "# ckpt_resnet_152_x256 = torch.load(\"/home/jflxb/Documents/lmu/HuBMAP/checkpoints/TransResUNet/resnet152_x256_channel_weighted.pt\")\n",
    "# ckpt_wide_resnet_101_2_x512 = torch.load(\"/home/jflxb/Documents/lmu/HuBMAP/checkpoints/TransResUNet/wide_resnet101_2_x512_channel_weighted.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_history_wide_resnet50_2_x256 = ckpt1[\"training_loss_history\"]\n",
    "validation_loss_history_wide_resnet50_2_x256 = ckpt1[\"validation_loss_history\"]\n",
    "\n",
    "training_loss_history_resnext101_32x8_x512 = ckpt2[\"training_loss_history\"]\n",
    "validation_loss_history_resnext101_32x8_x512 = ckpt2[\"validation_loss_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    d = [(i, e) for i, elems in enumerate(data) for e in elems]\n",
    "    df = pd.DataFrame(d, columns=[\"epoch\", \"value\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_history_resnet_152_x256_data = prepare_data(training_loss_history_wide_resnet50_2_x256)\n",
    "validation_loss_history_resnet_152_x256_data = prepare_data(validation_loss_history_wide_resnet50_2_x256)\n",
    "\n",
    "training_loss_history_wide_resnet_101_2_x512_data = prepare_data(training_loss_history_resnext101_32x8_x512)\n",
    "validation_loss_history_wide_resnet_101_2_x512_data = prepare_data(validation_loss_history_resnext101_32x8_x512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallette = sns.color_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1)\n",
    "# axs.grid()\n",
    "\n",
    "# sns.lineplot(\n",
    "#     training_loss_history_resnet_152_x256_data,\n",
    "#     x=\"epoch\",\n",
    "#     y=\"value\",\n",
    "#     ax=axs,\n",
    "#     linestyle=\"solid\",\n",
    "#     label=\"Training\",\n",
    "#     color=pallette[0],\n",
    "# )\n",
    "sns.lineplot(\n",
    "    validation_loss_history_resnet_152_x256_data, \n",
    "    x=\"epoch\", \n",
    "    y=\"value\", \n",
    "    ax=axs, \n",
    "    # linestyle=\"dashed\", \n",
    "    label=\"\\\\textbf{TransResU-Net-4x256} (Wide ResNet-50-2)\", \n",
    "    # color=pallette[0],\n",
    ")\n",
    "\n",
    "# sns.lineplot(\n",
    "#     training_loss_history_resnet_152_x256_data,\n",
    "#     x=\"epoch\",\n",
    "#     y=\"value\",\n",
    "#     ax=axs,\n",
    "#     linestyle=\"solid\",\n",
    "#     label=\"Training\",\n",
    "#     color=pallette[1],\n",
    "# )\n",
    "sns.lineplot(\n",
    "    validation_loss_history_wide_resnet_101_2_x512_data, \n",
    "    x=\"epoch\", \n",
    "    y=\"value\", \n",
    "    ax=axs, \n",
    "    # linestyle=\"dashed\", \n",
    "    label=\"\\\\textbf{TransResU-Net-4x512} (ResNeXt-101 32x8d)\", \n",
    "    # color=pallette[1],\n",
    ")\n",
    "\n",
    "axs.set_xlabel(\"Epoch\")\n",
    "axs.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"./trans_res_u-net_best_model_comparison.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubmap.dataset import TrainDataset\n",
    "import hubmap.dataset.transforms as T\n",
    "from hubmap.data import DATA_DIR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_256 = T.Compose([T.ToTensor(), T.Resize((256, 256))])\n",
    "tset_256 = TrainDataset(DATA_DIR, transform=compose_256, with_background=True)\n",
    "\n",
    "compose_512 = T.Compose([T.ToTensor(), T.Resize((512, 512))])\n",
    "tset_512 = TrainDataset(DATA_DIR, transform=compose_512, with_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_pixels_256 = []\n",
    "gl_pixels_256 = []\n",
    "uns_pixels_256 = []\n",
    "bg_pixels_256 = []\n",
    "\n",
    "for _, target in tset_256:\n",
    "    bv_pixels_256.append((target[0, :, :]).sum())\n",
    "    gl_pixels_256.append((target[1, :, :]).sum())\n",
    "    uns_pixels_256.append((target[2, :, :]).sum())\n",
    "    bg_pixels_256.append((target[3, :, :]).sum())\n",
    "    \n",
    "bv_pixels_256 = np.array(bv_pixels_256)\n",
    "gl_pixels_256 = np.array(gl_pixels_256)\n",
    "uns_pixels_256 = np.array(uns_pixels_256)\n",
    "bg_pixels_256 = np.array(bg_pixels_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels_per_mask_256 = 256 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256 = bv_pixels_256 / total_pixels_per_mask_256\n",
    "gl_per_image_ratio_256 = gl_pixels_256 / total_pixels_per_mask_256\n",
    "uns_per_image_ratio_256 = uns_pixels_256 / total_pixels_per_mask_256\n",
    "bg_per_image_ratio_256 = bg_pixels_256 / total_pixels_per_mask_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256_mean = np.mean(bv_per_image_ratio_256)\n",
    "gl_per_image_ratio_256_mean = np.mean(gl_per_image_ratio_256)\n",
    "uns_per_image_ratio_256_mean = np.mean(uns_per_image_ratio_256)\n",
    "bg_per_image_ratio_256_mean = np.mean(bg_per_image_ratio_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bv_per_image_ratio_256_mean: \", bv_per_image_ratio_256_mean)\n",
    "print(\"gl_per_image_ratio_256_mean: \", gl_per_image_ratio_256_mean)\n",
    "print(\"uns_per_image_ratio_256_mean: \", uns_per_image_ratio_256_mean)\n",
    "print(\"bg_per_image_ratio_256_mean: \", bg_per_image_ratio_256_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256_mean + gl_per_image_ratio_256_mean + uns_per_image_ratio_256_mean + bg_per_image_ratio_256_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight = 1 - bv_per_image_ratio_256_mean\n",
    "gl_per_image_weight = 1 - gl_per_image_ratio_256_mean\n",
    "uns_per_image_weight = 1 - uns_per_image_ratio_256_mean\n",
    "bg_per_image_weight = 1 - bg_per_image_ratio_256_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bv_per_image_weight: \", bv_per_image_weight)\n",
    "print(\"gl_per_image_weight: \", gl_per_image_weight)\n",
    "print(\"uns_per_image_weight: \", uns_per_image_weight)\n",
    "print(\"bg_per_image_weight: \", bg_per_image_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight + gl_per_image_weight + uns_per_image_weight + bg_per_image_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = 4 / (bv_per_image_weight + gl_per_image_weight + uns_per_image_weight + bg_per_image_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight_normed = normalizer * bv_per_image_weight\n",
    "gl_per_image_weight_normed = normalizer * gl_per_image_weight\n",
    "uns_per_image_weight_normed = normalizer * uns_per_image_weight\n",
    "bg_per_image_weight_normed = normalizer * bg_per_image_weight\n",
    "\n",
    "\n",
    "print(\"bv_per_image_weight_normed: \", bv_per_image_weight_normed)\n",
    "print(\"gl_per_image_weight_normed: \", gl_per_image_weight_normed)\n",
    "print(\"uns_per_image_weight_normed: \", uns_per_image_weight_normed)\n",
    "print(\"bg_per_image_weight_normed: \", bg_per_image_weight_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_pixels_512 = []\n",
    "gl_pixels_512 = []\n",
    "uns_pixels_512 = []\n",
    "bg_pixels_512 = []\n",
    "\n",
    "for _, target in tset_512:\n",
    "    bv_pixels_512.append((target[0, :, :]).sum())\n",
    "    gl_pixels_512.append((target[1, :, :]).sum())\n",
    "    uns_pixels_512.append((target[2, :, :]).sum())\n",
    "    bg_pixels_512.append((target[3, :, :]).sum())\n",
    "    \n",
    "bv_pixels_512 = np.array(bv_pixels_512)\n",
    "gl_pixels_512 = np.array(gl_pixels_512)\n",
    "uns_pixels_512 = np.array(uns_pixels_512)\n",
    "bg_pixels_512 = np.array(bg_pixels_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels_per_mask_512 = 512 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_512 = bv_pixels_512 / total_pixels_per_mask_512\n",
    "gl_per_image_ratio_512 = gl_pixels_512 / total_pixels_per_mask_512\n",
    "uns_per_image_ratio_512 = uns_pixels_512 / total_pixels_per_mask_512\n",
    "bg_per_image_ratio_512 = bg_pixels_512 / total_pixels_per_mask_512\n",
    "\n",
    "bv_per_image_ratio_512_mean = np.mean(bv_per_image_ratio_512)\n",
    "gl_per_image_ratio_512_mean = np.mean(gl_per_image_ratio_512)\n",
    "uns_per_image_ratio_512_mean = np.mean(uns_per_image_ratio_512)\n",
    "bg_per_image_ratio_512_mean = np.mean(bg_per_image_ratio_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bv_per_image_ratio_512_mean: \", bv_per_image_ratio_512_mean)\n",
    "print(\"gl_per_image_ratio_512_mean: \", gl_per_image_ratio_512_mean)\n",
    "print(\"uns_per_image_ratio_512_mean: \", uns_per_image_ratio_512_mean)\n",
    "print(\"bg_per_image_ratio_512_mean: \", bg_per_image_ratio_512_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_512_mean + gl_per_image_ratio_512_mean + uns_per_image_ratio_512_mean + bg_per_image_ratio_512_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "J",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
