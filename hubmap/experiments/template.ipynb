{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from hubmap.experiments.load_data import make_expert_loader\n",
    "from hubmap.experiments.load_data import make_annotated_loader\n",
    "from hubmap.experiments.training import Trainer\n",
    "from hubmap.dataset import transforms as T\n",
    "\n",
    "from torchmetrics.detection import MeanAveragePrecision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data that we need for the experiment. This includes the training data, the validation (test) data that we will use for training.\n",
    "\n",
    "For this, depending on the experiments we use different transformations on the data. The following transformations are a minimal example. Furhter transformations should be included for more sophisticated experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformations = T.Compose(\n",
    "    [T.ToTensor(), T.Resize((512, 512)), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "test_transformations = T.Compose(\n",
    "    [T.ToTensor(), T.Resize((512, 512)), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the experiment we may want to load all annotated images or just the ones that are annotated by experts.\n",
    "\n",
    "Here we create a function to load all the images that are annotated (not only the ones by experts).\n",
    "The created function can than be used to load the data loaders with a specific batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train, test split ratio is set to 0.8 by default.\n",
    "# Meaning 80% of the data is used for training and 20% for testing.\n",
    "load_annotated_data = make_annotated_loader(train_transformations, test_transformations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we determine the device we want to train on. \n",
    "If a GPU is available, we use it, otherwise we fall back to the CPU. \n",
    "We also set the random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the model we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jflxb/Documents/lmu/HuBMAP/hubmap/models/fully_convolutional_transformer.py:391: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "from hubmap.models import FCT, init_weights\n",
    "\n",
    "model = FCT().to(device)\n",
    "_ = model.apply(init_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the other modules needed for training, such as the loss measure, and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected argument `iou_thresholds` to either be `None` or a list of floats but got 0.6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[1;32m      2\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[0;32m----> 3\u001b[0m metric \u001b[39m=\u001b[39m MeanAveragePrecision(iou_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msegm\u001b[39;49m\u001b[39m\"\u001b[39;49m, iou_thresholds\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/J/lib/python3.11/site-packages/torchmetrics/detection/mean_ap.py:275\u001b[0m, in \u001b[0;36mMeanAveragePrecision.__init__\u001b[0;34m(self, box_format, iou_type, iou_thresholds, rec_thresholds, max_detection_thresholds, class_metrics, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miou_type \u001b[39m=\u001b[39m iou_type\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m iou_thresholds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(iou_thresholds, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    276\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected argument `iou_thresholds` to either be `None` or a list of floats but got \u001b[39m\u001b[39m{\u001b[39;00miou_thresholds\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miou_thresholds \u001b[39m=\u001b[39m iou_thresholds \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m0.5\u001b[39m, \u001b[39m0.95\u001b[39m, \u001b[39mround\u001b[39m((\u001b[39m0.95\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m0.05\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m rec_thresholds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(rec_thresholds, \u001b[39mlist\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Expected argument `iou_thresholds` to either be `None` or a list of floats but got 0.6"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "metric = mAP() # TODO: implement the mean Average Precision metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the trainer and start training. The trainer is responsible for running the training loop, saving checkpoints, and logging metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader, test_loader = load_annotated_data(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    metric=metric,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "J",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a58ea3f06b7c035f03696c8d262430e329e4f861a31188ab1909a2b4ddd27d3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
