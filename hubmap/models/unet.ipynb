{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../dataset')\n",
    "from datasets import TrainDataset, TestDataset, ValDataset\n",
    "import transforms as tran\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "transforms_augment = tran.Compose([\n",
    "    tran.ToTensor(mask_as_integer=False),\n",
    "    tran.Resize((256, 256)),\n",
    "    tran.RandomHorizontalFlip(),\n",
    "    tran.RandomVerticalFlip(),\n",
    "])\n",
    "\n",
    "transforms_val = tran.Compose([\n",
    "    tran.ToTensor(mask_as_integer=False),\n",
    "    tran.Resize((256, 256)),\n",
    "])\n",
    "train = TrainDataset('../data/', transform=transforms_augment, with_background=True, as_id_mask=False)\n",
    "#test = TestDataset('../data/', transform=transforms, with_background=True, as_id_mask=True)\n",
    "val = ValDataset('../data/', transform=transforms_val, with_background=True, as_id_mask=False)\n",
    "\n",
    "batch_size = 6\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking one batch from the training loader\n",
    "from collections import Counter\n",
    "\n",
    "images, masks = next(iter(train_loader))\n",
    "image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "mask = torch.argmax(masks[0], dim=0).cpu().numpy() # Assuming masks are one-hot encoded\n",
    "class_counts = Counter(mask.flatten())\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow((image * 0.5) + 0.5)  # Reverting normalization\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].imshow(mask)\n",
    "axes[1].set_title('Ground Truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        def up_block(in_channels, out_channels):\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.up4 = up_block(512, 256)\n",
    "        self.up3 = up_block(256, 128)\n",
    "        self.up2 = up_block(128, 64)\n",
    "        \n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.maxpool(enc1))\n",
    "        enc3 = self.encoder3(self.maxpool(enc2))\n",
    "        enc4 = self.encoder4(self.maxpool(enc3))\n",
    "        \n",
    "        up3 = self.up4(enc4)\n",
    "        dec3 = self.decoder3(torch.cat([up3, enc3], 1))\n",
    "        \n",
    "        up2 = self.up3(dec3)\n",
    "        dec2 = self.decoder2(torch.cat([up2, enc2], 1))\n",
    "        \n",
    "        up1 = self.up2(dec2)\n",
    "        dec1 = self.decoder1(torch.cat([up1, enc1], 1))\n",
    "        \n",
    "        return self.final_conv(dec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNetPlusPlus, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.middle = conv_block(512, 512)\n",
    "        \n",
    "        self.decoder4 = conv_block(1024, 256)\n",
    "        self.decoder3a = conv_block(768, 128)\n",
    "        self.decoder3b = conv_block(256, 128)\n",
    "        self.decoder2a = conv_block(384, 64)\n",
    "        self.decoder2b = conv_block(128, 64)\n",
    "        self.decoder2c = conv_block(64, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.maxpool(enc1))\n",
    "        enc3 = self.encoder3(self.maxpool(enc2))\n",
    "        enc4 = self.encoder4(self.maxpool(enc3))\n",
    "        \n",
    "        middle = self.middle(self.maxpool(enc4))\n",
    "\n",
    "        up4 = self.upconv4(middle)\n",
    "        concat4 = torch.cat([up4, enc4], 1)\n",
    "        dec4 = self.decoder4(concat4)\n",
    "        \n",
    "        up3a = self.upconv3(dec4)\n",
    "        concat3a = torch.cat([up3a, enc3, dec4], 1)\n",
    "        dec3a = self.decoder3a(concat3a)\n",
    "        \n",
    "        up3b = self.upconv3(dec3a)\n",
    "        concat3b = torch.cat([up3b, enc3], 1)\n",
    "        dec3b = self.decoder3b(concat3b)\n",
    "\n",
    "        up2a = self.upconv2(dec3a)\n",
    "        concat2a = torch.cat([up2a, enc2, dec3a], 1)\n",
    "        dec2a = self.decoder2a(concat2a)\n",
    "\n",
    "        up2b = self.upconv2(dec2a)\n",
    "        concat2b = torch.cat([up2b, enc2, dec3b], 1)\n",
    "        dec2b = self.decoder2b(concat2b)\n",
    "\n",
    "        up2c = self.upconv2(dec2b)\n",
    "        concat2c = torch.cat([up2c, enc2], 1)\n",
    "        dec2c = self.decoder2c(concat2c)\n",
    "\n",
    "        return self.final_conv(dec2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class UNet_BB(nn.Module):\n",
    "    def __init__(self, out_channels, encoder_name='resnet18', pretrained=True):\n",
    "        super(UNet_BB, self).__init__()\n",
    "\n",
    "        # Use pre-trained ResNet-X model as the encoder\n",
    "        if encoder_name == 'resnet18':\n",
    "            self.encoder = models.resnet18(pretrained=pretrained)\n",
    "        elif encoder_name == 'resnet34':\n",
    "            self.encoder = models.resnet34(pretrained=pretrained)\n",
    "        \n",
    "        # Define the decoder\n",
    "        self.upconv1 = self.conv_transpose_block(512, 256)\n",
    "        self.upconv2 = self.conv_transpose_block(256, 128)\n",
    "        self.upconv3 = self.conv_transpose_block(128, 64)\n",
    "        self.upconv4 = self.conv_transpose_block(64, 32)\n",
    "\n",
    "        # Final output layer\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_transpose_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the ResNet encoder\n",
    "        x1 = self.encoder.relu(self.encoder.bn1(self.encoder.conv1(x)))\n",
    "        x2 = self.encoder.layer1(x1)\n",
    "        x3 = self.encoder.layer2(x2)\n",
    "        x4 = self.encoder.layer3(x3)\n",
    "        x5 = self.encoder.layer4(x4)\n",
    "\n",
    "        # Pass through the decoder layers\n",
    "        x = self.upconv1(x5)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.upconv4(x)\n",
    "\n",
    "        # Final output layer\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = nn.functional.cross_entropy(input, target, reduction='none')  # Shape: (batch_size, H, W)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        alpha_t = self.alpha[target.view(-1)].view(target.size())  # Reshape alpha to match target shape\n",
    "        loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor and make sure it's a float\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "n_epochs = 50\n",
    "lr = 0.001\n",
    "\n",
    "# Model\n",
    "#model = UNet(in_channels=3, out_channels=4).to(device)\n",
    "#model = UNetPlusPlus(in_channels=3, out_channels=4).to(device)\n",
    "model = UNet_BB(out_channels=4,encoder_name=\"resnet18\", pretrained=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#weights = [0.5, 0.1, 0.1, 0.1]\n",
    "#weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "#criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "alpha = torch.tensor([3.3, 0.25, 0.2, 0.35]).to(device) # More weight to blood_vessel, glomerulus, and unsure\n",
    "criterion = FocalLoss(gamma=2, alpha=alpha)\n",
    "\n",
    "def compute_accuracy(pred, target):\n",
    "    correct = (pred == target).float().sum()\n",
    "    total = target.numel()\n",
    "    return (correct / total).item()\n",
    "\n",
    "# Initialize variables to track training and validation loss, accuracy, and IoU\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_ious = []  # Added for IoU\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_ious = []    # Added for IoU\n",
    "\n",
    "def iou_score(output, target):\n",
    "    ious = []\n",
    "    for class_idx in range(4):  # Assuming 4 classes\n",
    "        output_class = (output == class_idx)\n",
    "        target_class = (target == class_idx)\n",
    "        intersection = (output_class & target_class).float().sum()\n",
    "        union = (output_class | target_class).float().sum()\n",
    "        ious.append(intersection / (union + 1e-6))  # Avoid division by zero\n",
    "    return ious\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_train_accuracy = 0 # Added\n",
    "    mean_iou = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = torch.argmax(masks, dim=1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        preds = torch.argmax(outputs, dim=1) # Added\n",
    "        ious = iou_score(preds, masks)\n",
    "        mean_iou += torch.mean(torch.tensor(ious)).item()  # Use torch instead of numpy\n",
    "\n",
    "        accuracy = compute_accuracy(preds, masks) # Added\n",
    "        total_train_accuracy += accuracy # Added\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(total_train_accuracy / len(train_loader)) # Added\n",
    "    train_ious.append(mean_iou / len(train_loader))  # Added\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    total_accuracy = 0\n",
    "    mean_val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = torch.argmax(masks, dim=1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            class_counts = [torch.sum(preds == i).item() for i in range(4)]\n",
    "            print(f'Class counts in predictions: {class_counts}')\n",
    "\n",
    "            # Inside the validation loop\n",
    "            ious = iou_score(preds, masks)\n",
    "            mean_val_iou += torch.mean(torch.tensor(ious)).item()  # Use torch instead of numpy\n",
    "\n",
    "            accuracy = compute_accuracy(preds, masks)\n",
    "            total_accuracy += accuracy\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(total_accuracy / len(val_loader))\n",
    "    val_ious.append(mean_val_iou / len(val_loader))  # Added\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1]}, Val Loss: {val_losses[-1]}, Val Accuracy: {val_accuracies[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor and make sure it's a float\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "n_epochs = 50\n",
    "lr = 0.001\n",
    "\n",
    "# Model\n",
    "#model = UNet(in_channels=3, out_channels=4).to(device)\n",
    "#model = UNetPlusPlus(in_channels=3, out_channels=4).to(device)\n",
    "model = UNet_BB(out_channels=4,encoder_name=\"resnet18\", pretrained=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#weights = [0.5, 0.1, 0.1, 0.1]\n",
    "#weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "#criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "alpha = torch.tensor([3.3, 0.25, 0.2, 0.35]).to(device) # More weight to blood_vessel, glomerulus, and unsure\n",
    "criterion = FocalLoss(gamma=2, alpha=alpha)\n",
    "\n",
    "def iou_score(output, target):\n",
    "    ious = []\n",
    "    for class_idx in range(4):  # Assuming 4 classes\n",
    "        output_class = (output == class_idx)\n",
    "        target_class = (target == class_idx)\n",
    "        intersection = (output_class & target_class).float().sum()\n",
    "        union = (output_class | target_class).float().sum()\n",
    "        ious.append(intersection / (union + 1e-6))  # Avoid division by zero\n",
    "    return ious\n",
    "\n",
    "# Initialize variables to track training and validation loss and IoU\n",
    "train_losses = []\n",
    "train_ious = []\n",
    "val_losses = []\n",
    "val_ious = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_train_accuracy = 0 # Added\n",
    "    mean_iou = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = torch.argmax(masks, dim=1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        preds = torch.argmax(outputs, dim=1) # Added\n",
    "        ious = iou_score(preds, masks)\n",
    "        mean_iou += torch.mean(torch.tensor(ious)).item()  # Use torch instead of numpy\n",
    "\n",
    "        accuracy = compute_accuracy(preds, masks) # Added\n",
    "        total_train_accuracy += accuracy # Added\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(total_train_accuracy / len(train_loader)) # Added\n",
    "    train_ious.append(mean_iou / len(train_loader))  # Added\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    total_accuracy = 0\n",
    "    mean_val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = torch.argmax(masks, dim=1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            class_counts = [torch.sum(preds == i).item() for i in range(4)]\n",
    "            print(f'Class counts in predictions: {class_counts}')\n",
    "\n",
    "            # Inside the validation loop\n",
    "            ious = iou_score(preds, masks)\n",
    "            mean_val_iou += torch.mean(torch.tensor(ious)).item()  # Use torch instead of numpy\n",
    "\n",
    "            accuracy = compute_accuracy(preds, masks)\n",
    "            total_accuracy += accuracy\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(total_accuracy / len(val_loader))\n",
    "    val_ious.append(mean_val_iou / len(val_loader))  # Added\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1]}, Val Loss: {val_losses[-1]}, Val Accuracy: {val_accuracies[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "axs[0].plot(train_losses, label='Training Loss')\n",
    "axs[0].plot(val_losses, label='Validation Loss')\n",
    "axs[0].set_title('Training & Validation Loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "axs[1].plot(train_accuracies, label='Training Accuracy')\n",
    "axs[1].plot(val_accuracies, label='Validation Accuracy')\n",
    "axs[1].set_title('Training & Validation Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend()\n",
    "\n",
    "# Plotting the training and validation IoU\n",
    "axs[2].plot(train_ious, label='Training Mean IoU')\n",
    "axs[2].plot(val_ious, label='Validation Mean IoU')\n",
    "axs[2].set_title('Training & Validation Mean IoU')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('IoU')\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking one batch from the validation loader\n",
    "import numpy as np\n",
    "images, masks = next(iter(val_loader))\n",
    "images = images.to(device)\n",
    "masks = torch.argmax(masks, dim=1).to(device)\n",
    "\n",
    "# Predicting\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "# Selecting the first image in the batch\n",
    "image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "mask = masks[0].cpu().numpy()\n",
    "pred = preds[0].cpu().numpy()\n",
    "print(\"Unique values in prediction:\", np.unique(pred))\n",
    "\n",
    "# Convert the tensor of predictions to a numpy array\n",
    "preds_np = preds.cpu().numpy()\n",
    "\n",
    "# Flatten the array if it's 3D, so we can count occurrences of each class label\n",
    "preds_flat = preds_np.flatten()\n",
    "\n",
    "# Use np.bincount to count occurrences of each class label\n",
    "class_counts = np.bincount(preds_flat)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Class counts in predictions:\", class_counts)\n",
    "print(pred)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow((image * 0.5) + 0.5)  # Reverting normalization\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].imshow(mask)\n",
    "axes[1].set_title('Ground Truth')\n",
    "axes[2].imshow(pred)\n",
    "axes[2].set_title(\"Prediction\")\n",
    "plt.text(-100, 300, f'Unique values in prediction: {np.unique(pred)}', fontsize=15)\n",
    "plt.text(-700, 320, f'Class counts in predictions: {class_counts}', fontsize=15)\n",
    "#plt.text(0, 340, f'Weights: {weights.detach().cpu().numpy()}', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
